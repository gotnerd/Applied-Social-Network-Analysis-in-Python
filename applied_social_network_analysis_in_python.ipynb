{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied social network analysis in Python\n",
    "----\n",
    "\n",
    "**Applied social network analysis in Python** was the last course in the **Applied Data Science with Python** specialization. This notebook shows my work for the four assignments that I had to solve during this course:\n",
    "\n",
    "* **Assignment 1: Creating and manipulating graphs**\n",
    "\n",
    "In this assignment, I've acquired experience in creating bipartite graphs, how to add node attributes and how to find a weighted projection of the graph.\n",
    "\n",
    "* **Assignment 2:  Network Connectivity**\n",
    "\n",
    "For this assignment I've analyzed the internal email communication network between employees of a mid-sized manufacturing company. \n",
    "\n",
    "* **Assignment 3:  Influence Measures and Network Centralization**\n",
    "\n",
    "In this part of the assignment I've computed various measures of centrality on two networks: *a friendship network in Part 1*, and a *blog network in Part 2*.\n",
    "\n",
    "* **Assignment 4: Network Evolution**\n",
    "\n",
    "This assignment was split in two parts. In the first part of the assignment I've analyzed randomly generated graphs and determined which algorithm created them. For the second part of this assignment I've worked with a company's email network to predict salaries and new connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1 \n",
    "----\n",
    "\n",
    "Eight employees at a small company were asked to choose 3 movies that they would most enjoy watching for the upcoming company movie night. These choices are stored in the file `Employee_Movie_Choices.txt`.\n",
    "\n",
    "A second file, `Employee_Relationships.txt`, has data on the relationships between different coworkers. \n",
    "\n",
    "The relationship score has value of `-100` (Enemies) to `+100` (Best Friends). A value of zero means the two employees haven't interacted or are indifferent.\n",
    "\n",
    "Both files are tab delimited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "\n",
    "# This is the set of employees\n",
    "employees = set(['Pablo',\n",
    "                 'Lee',\n",
    "                 'Georgia',\n",
    "                 'Vincent',\n",
    "                 'Andy',\n",
    "                 'Frida',\n",
    "                 'Joan',\n",
    "                 'Claude'])\n",
    "\n",
    "# This is the set of movies\n",
    "movies = set(['The Shawshank Redemption',\n",
    "              'Forrest Gump',\n",
    "              'The Matrix',\n",
    "              'Anaconda',\n",
    "              'The Social Network',\n",
    "              'The Godfather',\n",
    "              'Monty Python and the Holy Grail',\n",
    "              'Snakes on a Plane',\n",
    "              'Kung Fu Panda',\n",
    "              'The Dark Knight',\n",
    "              'Mean Girls'])\n",
    "\n",
    "\n",
    "# you can use the following function to plot graphs\n",
    "# make sure to comment it out before submitting to the autograder\n",
    "def plot_graph(G, weight_name=None):\n",
    "    '''\n",
    "    G: a networkx G\n",
    "    weight_name: name of the attribute for plotting edge weights (if G is weighted)\n",
    "    '''\n",
    "    %matplotlib notebook\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure()\n",
    "    pos = nx.spring_layout(G)\n",
    "    edges = G.edges()\n",
    "    weights = None\n",
    "    \n",
    "    if weight_name:\n",
    "        weights = [int(G[u][v][weight_name]) for u,v in edges]\n",
    "        labels = nx.get_edge_attributes(G,weight_name)\n",
    "        nx.draw_networkx_edge_labels(G,pos,edge_labels=labels)\n",
    "        nx.draw_networkx(G, pos, edges=edges, width=weights);\n",
    "    else:\n",
    "        nx.draw_networkx(G, pos, edges=edges);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Using NetworkX, load in the bipartite graph from `Employee_Movie_Choices.txt` and return that graph.\n",
    "\n",
    "*This function should return a networkx graph with 19 nodes and 24 edges*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_one():\n",
    "    # Your Code Here\n",
    "    df = pd.read_table('datasets/Employee_Movie_Choices.txt')\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(df['#Employee'].values, bipartite=0)\n",
    "    G.add_nodes_from(df['Movie'].values, bipartite=1)\n",
    "    for idx, row in df.iterrows():\n",
    "        G.add_edge(row['#Employee'],row['Movie'])\n",
    "    return G\n",
    "\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Using the graph from the previous question, add nodes attributes named `'type'` where movies have the value `'movie'` and employees have the value `'employee'` and return that graph.\n",
    "\n",
    "*This function should return a networkx graph with node attributes `{'type': 'movie'}` or `{'type': 'employee'}`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    # Your Code Here\n",
    "    df = pd.read_table('datasets/Employee_Movie_Choices.txt')\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(df['#Employee'].values, bipartite=0, role='employee')\n",
    "    G.add_nodes_from(df['Movie'].values, bipartite=1, role='movie')\n",
    "    for idx, row in df.iterrows():\n",
    "        G.add_edge(row['#Employee'],row['Movie'])  \n",
    "    return G\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 3\n",
    "\n",
    "Find a weighted projection of the graph from `answer_two` which tells us how many movies different pairs of employees have in common.\n",
    "\n",
    "*This function should return a weighted projected graph.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "    # Your Code Here\n",
    "    df = pd.read_table('datasets/Employee_Movie_Choices.txt')\n",
    "    X = set(df['#Employee'].values)\n",
    "    G = answer_two()\n",
    "    P = bipartite.weighted_projected_graph(G, X)\n",
    "    return P\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Suppose you'd like to find out if people that have a high relationship score also like the same types of movies.\n",
    "\n",
    "Find the Pearson correlation ( using `DataFrame.corr()` ) between employee relationship scores and the number of movies they have in common. If two employees have no movies in common it should be treated as a 0, not a missing value, and should be included in the correlation calculation.\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_four(): \n",
    "    # Your Code Here\n",
    "    df = pd.read_table('datasets/Employee_Relationships.txt',\n",
    "                       header=None, names=['first_empl', 'sec_empl', 'rel'])\n",
    "    P = answer_three()\n",
    "    num_movies = []\n",
    "    df['num_movies']  = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        if (row['first_empl'], row['sec_empl']) in P.edges():\n",
    "            df.loc[idx, 'num_movies'] = P.edge[row['first_empl']][row['sec_empl']]['weight']\n",
    "        elif (row['sec_empl'], row['first_empl']) in P.edges():\n",
    "             df.loc[idx, 'num_movies'] = P.edge[row['sec_empl']][row['first_empl']]['weight']\n",
    "        else:\n",
    "            df.loc[idx, 'num_movies'] = 0\n",
    "    return float(df['rel'].corr(df['num_movies']))\n",
    "\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "----\n",
    "\n",
    "In this assignment you will go through the process of importing and analyzing an internal email communication network between employees of a mid-sized manufacturing company. \n",
    "Each node represents an employee and each directed edge between two nodes represents an individual email. The left node represents the sender and the right node represents the recipient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Using networkx, load up the directed multigraph from `email_network.txt`. Make sure the node names are strings.\n",
    "\n",
    "*This function should return a directed multigraph networkx graph.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_one(): \n",
    "    # Your Code Here\n",
    "    G = nx.read_edgelist('datasets/email_network.txt', create_using=nx.MultiDiGraph(), data=(('weight',float),))\n",
    "    return G\n",
    "\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "How many employees and emails are represented in the graph from Question 1?\n",
    "\n",
    "*This function should return a tuple (#employees, #emails).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    # Your Code Here\n",
    "    G = answer_one()\n",
    "    return (len(G.nodes()), len(G.edges()))\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "* Part 1. Assume that information in this company can only be exchanged through email.\n",
    "\n",
    "    When an employee sends an email to another employee, a communication channel has been created, allowing the sender to provide information to the receiver, but not vice versa. \n",
    "\n",
    "    Based on the emails sent in the data, is it possible for information to go from every employee to every other employee?\n",
    "\n",
    "\n",
    "* Part 2. Now assume that a communication channel established by an email allows information to be exchanged both ways. \n",
    "\n",
    "    Based on the emails sent in the data, is it possible for information to go from every employee to every other employee?\n",
    "\n",
    "\n",
    "*This function should return a tuple of bools (part1, part2).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "    # Your Code Here\n",
    "    G = answer_one()\n",
    "    return (nx.is_strongly_connected(G), nx.is_weakly_connected(G))\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "How many nodes are in the largest (in terms of nodes) weakly connected component?\n",
    "\n",
    "*This function should return an int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def answer_four():\n",
    "    # Your Code Here\n",
    "    G = answer_one()\n",
    "    largest = max(nx.weakly_connected_component_subgraphs(G), key=len)\n",
    "    return len(largest.nodes())\n",
    "\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "How many nodes are in the largest (in terms of nodes) strongly connected component?\n",
    "\n",
    "*This function should return an int*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_five():\n",
    "    # Your Code Here\n",
    "    G = answer_one()\n",
    "    largest = max(nx.strongly_connected_component_subgraphs(G), key=len)\n",
    "    return len(largest.nodes())\n",
    "\n",
    "answer_five()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Using the NetworkX function strongly_connected_component_subgraphs, find the subgraph of nodes in a largest strongly connected component. \n",
    "Call this graph G_sc.\n",
    "\n",
    "*This function should return a networkx MultiDiGraph named G_sc.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_six():\n",
    "    # Your Code Here\n",
    "    G = answer_one()\n",
    "    G_sc = max(nx.strongly_connected_component_subgraphs(G), key=len) \n",
    "    return G_sc\n",
    "\n",
    "answer_six()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "What is the average distance between nodes in G_sc?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_seven():\n",
    "    # Your Code Here\n",
    "    G_sc = answer_six()\n",
    "    return nx.average_shortest_path_length(G_sc)\n",
    "\n",
    "answer_seven()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "What is the largest possible distance between two employees in G_sc?\n",
    "\n",
    "*This function should return an int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_eight():\n",
    "    # Your Code Here\n",
    "    G_sc = answer_six()\n",
    "    return nx.diameter(G_sc)\n",
    "\n",
    "answer_eight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "What is the set of nodes in G_sc with eccentricity equal to the diameter?\n",
    "\n",
    "*This function should return a set of the node(s).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_nine():\n",
    "    # Your Code Here\n",
    "    G_sc = answer_six()\n",
    "    return set(nx.periphery(G_sc))\n",
    "\n",
    "answer_nine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "What is the set of node(s) in G_sc with eccentricity equal to the radius?\n",
    "\n",
    "*This function should return a set of the node(s).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_ten():\n",
    "    # Your Code Here\n",
    "    G_sc = answer_six()\n",
    "    return set(nx.center(G_sc))\n",
    "\n",
    "answer_ten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Which node in G_sc is connected to the most other nodes by a shortest path of length equal to the diameter of G_sc?\n",
    "\n",
    "How many nodes are connected to this node?\n",
    "\n",
    "\n",
    "*This function should return a tuple (name of node, number of satisfied connected nodes).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_eleven():\n",
    "    # Your Code Here\n",
    "    G_sc = answer_six()\n",
    "    diameter = nx.diameter(G_sc)\n",
    "    paths = nx.shortest_path_length(G_sc)\n",
    "    max_node, max_num = 0, 0\n",
    "    for node in paths.keys():\n",
    "        satis_conn = len([x for x in paths[node].keys() if paths[node][x]==diameter])\n",
    "        if satis_conn>max_num:\n",
    "            max_node, max_num = node, satis_conn   \n",
    "    return (max_node, max_num)\n",
    "\n",
    "answer_eleven()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Suppose you want to prevent communication from flowing to the node that you found in the previous question from any node in the center of G_sc, what is the smallest number of nodes you would need to remove from the graph (you're not allowed to remove the node from the previous question or the center nodes)? \n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_twelve():\n",
    "    # Your Code Here\n",
    "    G_sc = answer_six()\n",
    "    return int(nx.node_connectivity(G_sc, '38', '97')-1)\n",
    "\n",
    "answer_twelve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "Construct an undirected graph G_un using G_sc (you can ignore the attributes).\n",
    "\n",
    "*This function should return a networkx Graph.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_thirteen():\n",
    "    # Your Code Here\n",
    "    G_sc = answer_six()\n",
    "    G_un = G_sc.to_undirected()\n",
    "    return nx.Graph(G_un)\n",
    "\n",
    "answer_thirteen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "\n",
    "What is the transitivity and average clustering coefficient of graph G_un?\n",
    "\n",
    "*This function should return a tuple (transitivity, avg clustering).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_fourteen():\n",
    "    # Your Code Here\n",
    "    G_un = answer_thirteen()\n",
    "    return (nx.transitivity(G_un), nx.average_clustering(G_un))\n",
    "\n",
    "answer_fourteen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "----\n",
    "\n",
    "In this assignment you will explore measures of centrality on two networks, a friendship network in Part 1, and a blog network in Part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "Answer questions 1-4 using the network `G1`, a network of friendships at a university department. Each node corresponds to a person, and an edge indicates friendship. \n",
    "\n",
    "*The network has been loaded as networkx graph object `G1`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G1 = nx.read_gml('datasets/friendships.gml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Find the degree centrality, closeness centrality, and normalized betweeness centrality (excluding endpoints) of node 100.\n",
    "\n",
    "*This function should return a tuple of floats `(degree_centrality, closeness_centrality, betweenness_centrality)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_one():\n",
    "    # Your Code Here\n",
    "    centrality = nx.degree_centrality(G1)[100]\n",
    "    closeness = nx.closeness_centrality(G1)[100]\n",
    "    betweenness = nx.betweenness_centrality(G1)[100] \n",
    "    return (centrality, closeness, betweenness)\n",
    "\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Questions 2, 3, and 4, assume that you do not know anything about the structure of the network, except for the all the centrality values of the nodes. That is, use one of the covered centrality measures to rank the nodes and find the most appropriate candidate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Suppose you are employed by an online shopping website and are tasked with selecting one user in network G1 to send an online shopping voucher to. We expect that the user who receives the voucher will send it to their friends in the network.  You want the voucher to reach as many nodes as possible. The voucher can be forwarded to multiple users at the same time, but the travel distance of the voucher is limited to one step, which means if the voucher travels more than one step in this network, it is no longer valid. Apply your knowledge in network centrality to select the best candidate for the voucher. \n",
    "\n",
    "*This function should return an integer, the name of the node.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def answer_two():    \n",
    "    # Your Code Here\n",
    "    centrality = nx.degree_centrality(G1)\n",
    "    return max(centrality.keys(), key=(lambda key: centrality[key]))\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Now the limit of the voucher’s travel distance has been removed. Because the network is connected, regardless of who you pick, every node in the network will eventually receive the voucher. However, we now want to ensure that the voucher reaches the nodes in the lowest average number of hops.\n",
    "\n",
    "How would you change your selection strategy? Write a function to tell us who is the best candidate in the network under this condition.\n",
    "\n",
    "*This function should return an integer, the name of the node.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def answer_three():  \n",
    "    # Your Code Here\n",
    "    closeness = nx.closeness_centrality(G1)\n",
    "    return max(closeness.keys(), key=(lambda key: closeness[key]))\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Assume the restriction on the voucher’s travel distance is still removed, but now a competitor has developed a strategy to remove a person from the network in order to disrupt the distribution of your company’s voucher. Your competitor is specifically targeting people who are often bridges of information flow between other pairs of people. Identify the single riskiest person to be removed under your competitor’s strategy?\n",
    "\n",
    "*This function should return an integer, the name of the node.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_four():\n",
    "    # Your Code Here\n",
    "    betweenness = nx.betweenness_centrality(G1)\n",
    "    return max(betweenness.keys(), key=(lambda key: betweenness[key]))\n",
    "\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2\n",
    "\n",
    "`G2` is a directed network of political blogs, where nodes correspond to a blog and edges correspond to links between blogs. Use your knowledge of PageRank and HITS to answer Questions 5-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G2 = nx.read_gml('datasets/blogs.gml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Apply the Scaled Page Rank Algorithm to this network. Find the Page Rank of node 'realclearpolitics.com' with damping value 0.85.\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_five():\n",
    "    # Your Code Here\n",
    "    return nx.pagerank(G2, alpha=0.85)['realclearpolitics.com']\n",
    "\n",
    "answer_five()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Apply the Scaled Page Rank Algorithm to this network with damping value 0.85. Find the 5 nodes with highest Page Rank. \n",
    "\n",
    "*This function should return a list of the top 5 blogs in desending order of Page Rank.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_six():    \n",
    "    # Your Code Here\n",
    "    import numpy as np\n",
    "    pageranks = nx.pagerank(G2, alpha=0.85)\n",
    "    pages = np.array(list(pageranks.keys()))\n",
    "    ranks = np.array(list(pageranks.values()))\n",
    "    return list(pages[ranks.argsort()[-5:][::-1]])\n",
    "\n",
    "answer_six()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 7\n",
    "\n",
    "Apply the HITS Algorithm to the network to find the hub and authority scores of node 'realclearpolitics.com'. \n",
    "\n",
    "*Your result should return a tuple of floats `(hub_score, authority_score)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_seven():\n",
    "    # Your Code Here\n",
    "    hubs, authorities = nx.hits(G2)\n",
    "    return (hubs['realclearpolitics.com'], authorities['realclearpolitics.com'])\n",
    "\n",
    "answer_seven()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 8 \n",
    "\n",
    "Apply the HITS Algorithm to this network to find the 5 nodes with highest hub scores.\n",
    "\n",
    "*This function should return a list of the top 5 blogs in desending order of hub scores.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_eight():\n",
    "    # Your Code Here\n",
    "    import numpy as np\n",
    "    hubs, authorities = nx.hits(G2)\n",
    "    blogs = np.array(list(hubs.keys()))\n",
    "    hubs = np.array(list(hubs.values()))\n",
    "    return list(blogs[hubs.argsort()[-5:][::-1]])\n",
    "\n",
    "answer_eight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9 \n",
    "\n",
    "Apply the HITS Algorithm to this network to find the 5 nodes with highest authority scores.\n",
    "\n",
    "*This function should return a list of the top 5 blogs in desending order of authority scores.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_nine():\n",
    "    # Your Code Here\n",
    "    import numpy as np\n",
    "    hubs, auth = nx.hits(G2)\n",
    "    blogs = np.array(list(auth.keys()))\n",
    "    auth = np.array(list(auth.values()))\n",
    "    return list(blogs[auth.argsort()[-5:][::-1]])\n",
    "\n",
    "answer_nine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1 - Random Graph Identification\n",
    "\n",
    "For the first part of this assignment you will analyze randomly generated graphs and determine which algorithm created them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<networkx.classes.graph.Graph at 0x7f1c0d2f9198>,\n",
       " <networkx.classes.graph.Graph at 0x7f1c0d2f9278>,\n",
       " <networkx.classes.graph.Graph at 0x7f1c0d2f9390>,\n",
       " <networkx.classes.graph.Graph at 0x7f1c0d2f93c8>,\n",
       " <networkx.classes.graph.Graph at 0x7f1c0d2f9400>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1_Graphs = pickle.load(open('datasets/A4_graphs','rb'))\n",
    "P1_Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`P1_Graphs` is a list containing 5 networkx graphs. Each of these graphs were generated by one of three possible algorithms:\n",
    "* Preferential Attachment (`'PA'`)\n",
    "* Small World with low probability of rewiring (`'SW_L'`)\n",
    "* Small World with high probability of rewiring (`'SW_H'`)\n",
    "\n",
    "Anaylze each of the 5 graphs and determine which of the three algorithms generated the graph.\n",
    "\n",
    "*The `graph_identification` function should return a list of length 5 where each element in the list is either `'PA'`, `'SW_L'`, or `'SW_H'`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_identification():\n",
    "    return ['PA', 'SW_L', 'SW_L', 'PA', 'SW_H']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2 - Company Emails\n",
    "\n",
    "For the second part of this assignment you will be workking with a company's email network where each node corresponds to a person at the company, and each edge indicates that at least one email has been sent between two people.\n",
    "\n",
    "The network also contains the node attributes `Department` and `ManagementSalary`.\n",
    "\n",
    "`Department` indicates the department in the company which the person belongs to, and `ManagementSalary` indicates whether that person is receiving a management position salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 1005\n",
      "Number of edges: 16706\n",
      "Average degree:  33.2458\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_gpickle('datasets/email_prediction.txt')\n",
    "\n",
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2A - Salary Prediction\n",
    "\n",
    "Using network `G`, identify the people in the network with missing values for the node attribute `ManagementSalary` and predict whether or not these individuals are receiving a management position salary.\n",
    "\n",
    "To accomplish this, you will need to create a matrix of node features using networkx, train a sklearn classifier on nodes that have `ManagementSalary` data, and predict a probability of the node receiving a management salary for nodes where `ManagementSalary` is missing.\n",
    "\n",
    "\n",
    "\n",
    "Your predictions will need to be given as the probability that the corresponding employee is receiving a management position salary.\n",
    "\n",
    "The evaluation metric for this assignment is the Area Under the ROC Curve (AUC).\n",
    "\n",
    "Your grade will be based on the AUC score computed for your classifier. A model which with an AUC of 0.88 or higher will receive full points, and with an AUC of 0.82 or higher will pass (get 80% of the full points).\n",
    "\n",
    "Using your trained classifier, return a series of length 252 with the data being the probability of receiving management salary, and the index being the node id.\n",
    "\n",
    "    Example:\n",
    "    \n",
    "        1       1.0\n",
    "        2       0.0\n",
    "        5       0.8\n",
    "        8       1.0\n",
    "            ...\n",
    "        996     0.7\n",
    "        1000    0.5\n",
    "        1001    0.0\n",
    "        Length: 252, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def salary_predictions():\n",
    "    # Your Code Here\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    input_data = pd.DataFrame()\n",
    "    target = nx.get_node_attributes(G, 'ManagementSalary')\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    closeness_centrality = nx.closeness_centrality(G)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    for node in target.keys():\n",
    "        row_features = pd.DataFrame([[degree_centrality[node], closeness_centrality[node],\n",
    "                                      betweenness_centrality[node], target[node]]], index=[node])\n",
    "        input_data = pd.concat([input_data, row_features], axis=0)\n",
    "    train_data = input_data[~input_data[3].isnull()]\n",
    "    test_data = input_data[input_data[3].isnull()]\n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf.fit(train_data[[0,1,2]].values, train_data[3].values)\n",
    "    preds = clf.predict_proba(test_data[[0,1,2]].values)[:,1]  \n",
    "    return pd.Series(preds, index=test_data.index)\n",
    "\n",
    "salary_predictions().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2B - New Connections Prediction\n",
    "\n",
    "For the last part of this assignment, you will predict future connections between employees of the network. The future connections information has been loaded into the variable `future_connections`. The index is a tuple indicating a pair of nodes that currently do not have a connection, and the `Future Connection` column indicates if an edge between those two nodes will exist in the future, where a value of 1.0 indicates a future connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Future Connection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(6, 840)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(4, 197)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(620, 979)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(519, 872)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(382, 423)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(97, 226)</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(349, 905)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(429, 860)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(309, 989)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(468, 880)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Future Connection\n",
       "(6, 840)                  0.0\n",
       "(4, 197)                  0.0\n",
       "(620, 979)                0.0\n",
       "(519, 872)                0.0\n",
       "(382, 423)                0.0\n",
       "(97, 226)                 1.0\n",
       "(349, 905)                0.0\n",
       "(429, 860)                0.0\n",
       "(309, 989)                0.0\n",
       "(468, 880)                0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_connections = pd.read_csv('datasets/Future_Connections.csv', index_col=0, converters={0: eval})\n",
    "future_connections.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using network `G` and `future_connections`, identify the edges in `future_connections` with missing values and predict whether or not these edges will have a future connection.\n",
    "\n",
    "To accomplish this, you will need to create a matrix of features for the edges found in `future_connections` using networkx, train a sklearn classifier on those edges in `future_connections` that have `Future Connection` data, and predict a probability of the edge being a future connection for those edges in `future_connections` where `Future Connection` is missing.\n",
    "\n",
    "\n",
    "\n",
    "Your predictions will need to be given as the probability of the corresponding edge being a future connection.\n",
    "\n",
    "The evaluation metric for this assignment is the Area Under the ROC Curve (AUC).\n",
    "\n",
    "Your grade will be based on the AUC score computed for your classifier. A model which with an AUC of 0.88 or higher will receive full points, and with an AUC of 0.82 or higher will pass (get 80% of the full points).\n",
    "\n",
    "Using your trained classifier, return a series of length 122112 with the data being the probability of the edge being a future connection, and the index being the edge as represented by a tuple of nodes.\n",
    "\n",
    "    Example:\n",
    "    \n",
    "        (107, 348)    0.35\n",
    "        (542, 751)    0.40\n",
    "        (20, 426)     0.55\n",
    "        (50, 989)     0.35\n",
    "                  ...\n",
    "        (939, 940)    0.15\n",
    "        (555, 905)    0.35\n",
    "        (75, 101)     0.65\n",
    "        Length: 122112, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_connections_predictions():  \n",
    "     # Your Code Here\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    \n",
    "    future_connections['pref_attachment'] = [list(nx.preferential_attachment(G, [node_pair]))[0][2]\n",
    "                                             for node_pair in future_connections.index]\n",
    "    future_connections['comm_neighbors'] = [len(list(nx.common_neighbors(G, node_pair[0], node_pair[1]))) \n",
    "                                            for node_pair in future_connections.index]\n",
    "    train_data = future_connections[~future_connections['Future Connection'].isnull()]\n",
    "    test_data = future_connections[future_connections['Future Connection'].isnull()]\n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf.fit(train_data[['pref_attachment','comm_neighbors']].values, train_data['Future Connection'].values)\n",
    "    preds = clf.predict_proba(test_data[['pref_attachment','comm_neighbors']].values)[:,1]\n",
    "    return pd.Series(preds, index=test_data.index)\n",
    "\n",
    "new_connections_predictions().head(10)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-social-network-analysis",
   "graded_item_id": "YNa9b",
   "launcher_item_id": "hvNc1",
   "part_id": "VbyiB"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
